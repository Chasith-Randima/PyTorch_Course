{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chasith-Randima/PyTorch_Course/blob/main/01_pytorch_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hVV5wAudh6Jh",
        "outputId": "9d52cb27-8be8-4245-c5a0-c82a8792a226"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVGiEiBYiEBi",
        "outputId": "913e1133-7830-4126-d523-77236ab0e10f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]), tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]), 50, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start,end,step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "\n",
        "X[:10],y[:10],len(X),len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKxn04KIiD9i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpwR9jYpqXGc",
        "outputId": "7a32a69b-f4cb-4acd-d8e8-6eb0849c65b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_split = int(0.8 * len(X))\n",
        "X_train,y_train = X[:train_split],y[:train_split]\n",
        "X_test,y_test = X[train_split:],y[train_split:]\n",
        "\n",
        "len(X_train),len(y_train),len(X_test),len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyt4Lh0wqXCX"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(train_data=X_train,train_labels=y_train,test_data=X_test,test_labels=y_test,predictions=None):\n",
        "  \"\"\" Plot training data , test data and compares predictions. \"\"\"\n",
        "  plt.figure(figsize=(10,7))\n",
        "\n",
        "  plt.scatter(train_data,train_labels,c=\"b\",s=4,label=\"Training Data\")\n",
        "\n",
        "  plt.scatter(test_data,test_labels,c=\"g\",s=4,label=\"Testing Data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    plt.scatter(test_data,predictions,c=\"r\",s=4,label=\"Predictions\")\n",
        "\n",
        "  plt.legend(prop={\"size\":14})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "6xP1rdGDqXBK",
        "outputId": "525421b8-c882-44c6-a7c6-d99e1a8466f0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_predictions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbjOcprriD8N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGiZ4gE315OL"
      },
      "outputs": [],
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1,requires_grad=True,\n",
        "                                            dtype=torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1,requires_grad=True,\n",
        "                                         dtype=torch.float))\n",
        "    \n",
        "  def forward(self,x:torch.Tensor) -> torch.Tensor:\n",
        "    return self.weights * x + self.bias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5NVbgxX15LS",
        "outputId": "fffa807c-86af-4dcb-db80-a971b049c402"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True), Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "list(model_0.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJvlwkUh-cP4",
        "outputId": "54291741-b3c2-42ef-ef9c-9de8249006bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5ZGaA8i_zdp",
        "outputId": "c61b42fb-e76e-40eb-d01a-739ea26b6e46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.8000],\n",
              "         [0.8200],\n",
              "         [0.8400],\n",
              "         [0.8600],\n",
              "         [0.8800],\n",
              "         [0.9000],\n",
              "         [0.9200],\n",
              "         [0.9400],\n",
              "         [0.9600],\n",
              "         [0.9800]]), tensor([[0.8600],\n",
              "         [0.8740],\n",
              "         [0.8880],\n",
              "         [0.9020],\n",
              "         [0.9160],\n",
              "         [0.9300],\n",
              "         [0.9440],\n",
              "         [0.9580],\n",
              "         [0.9720],\n",
              "         [0.9860]]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_test,y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShHjiqrmBqhe",
        "outputId": "b1098ddf-107f-41b6-9413-17e3ef08b41b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3982],\n",
              "        [0.4049],\n",
              "        [0.4116],\n",
              "        [0.4184],\n",
              "        [0.4251],\n",
              "        [0.4318],\n",
              "        [0.4386],\n",
              "        [0.4453],\n",
              "        [0.4520],\n",
              "        [0.4588]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "7TrPEyosCgOR",
        "outputId": "955edbd4-5cc3-4f3e-b71f-e56c954ad079"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_predictions(predictions=y_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0By2tsnHDQQv",
        "outputId": "d6a31434-a783-4e27-8bf4-a2ffb1768a9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True), Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "list(model_0.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11SDEhzOWSRu",
        "outputId": "081bb4af-b054-4c20-9fa8-0ddd59df0d8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-sTRKJLWd2w"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEZE6v3HC6On"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(params=model_0.parameters(),lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn_pY2CdC7pV",
        "outputId": "846aff5f-1d8a-44ad-8852-19b5ca3d6996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95840 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95850 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95860 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95870 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95880 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95890 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95900 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95910 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95920 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95930 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95940 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95950 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95960 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95970 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95980 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 95990 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96000 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96010 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96020 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96030 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96040 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96050 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96060 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96070 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96080 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96090 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96100 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96110 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96120 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96130 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96140 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96150 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96160 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96170 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96180 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96190 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96200 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96210 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96220 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96230 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96240 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96250 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96260 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96270 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96280 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96290 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96300 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96310 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96320 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96330 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96340 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96350 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96360 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96370 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96380 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96390 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96400 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96410 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96420 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96430 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96440 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96450 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96460 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96470 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96480 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96490 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96500 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96510 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96520 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96530 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96540 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96550 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96560 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96570 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96580 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96590 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96600 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96610 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96620 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96630 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96640 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96650 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96660 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96670 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96680 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96690 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96700 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96710 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96720 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96730 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96740 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96750 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96760 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96770 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96780 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96790 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96800 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96810 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96820 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96830 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96840 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96850 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96860 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96870 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96880 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96890 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96900 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96910 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96920 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96930 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96940 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96950 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96960 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96970 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96980 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 96990 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97000 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97010 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97020 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97030 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97040 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97050 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97060 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97070 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97080 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97090 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97100 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97110 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97120 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97130 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97140 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97150 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97160 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97170 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97180 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97190 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97200 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97210 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97220 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97230 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97240 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97250 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97260 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97270 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97280 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97290 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97300 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97310 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97320 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97330 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97340 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97350 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97360 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97370 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97380 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97390 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97400 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97410 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97420 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97430 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97440 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97450 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97460 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97470 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97480 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97490 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97500 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97510 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97520 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97530 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97540 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97550 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97560 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97570 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97580 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97590 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97600 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97610 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97620 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97630 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97640 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97650 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97660 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97670 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97680 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97690 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97700 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97710 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97720 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97730 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97740 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97750 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97760 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97770 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97780 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97790 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97800 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97810 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97820 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97830 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97840 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97850 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97860 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97870 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97880 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97890 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97900 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97910 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97920 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97930 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97940 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97950 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97960 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97970 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97980 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 97990 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98000 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98010 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98020 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98030 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98040 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98050 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98060 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98070 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98080 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98090 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98100 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98110 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98120 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98130 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98140 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98150 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98160 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98170 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98180 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98190 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98200 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98210 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98220 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98230 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98240 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98250 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98260 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98270 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98280 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98290 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98300 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98310 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98320 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98330 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98340 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98350 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98360 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98370 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98380 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98390 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98400 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98410 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98420 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98430 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98440 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98450 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98460 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98470 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98480 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98490 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98500 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98510 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98520 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98530 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98540 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98550 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98560 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98570 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98580 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98590 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98600 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98610 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98620 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98630 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98640 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98650 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98660 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98670 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98680 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98690 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98700 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98710 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98720 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98730 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98740 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98750 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98760 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98770 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98780 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98790 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98800 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98810 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98820 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98830 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98840 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98850 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98860 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98870 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98880 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98890 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98900 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98910 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98920 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98930 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98940 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98950 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98960 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98970 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98980 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 98990 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99000 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99010 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99020 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99030 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99040 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99050 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99060 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99070 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99080 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99090 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99100 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99110 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99120 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99130 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99140 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99150 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99160 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99170 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99180 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99190 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99200 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99210 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99220 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99230 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99240 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99250 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99260 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99270 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99280 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99290 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99300 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99310 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99320 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99330 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99340 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99350 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99360 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99370 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99380 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99390 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99400 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99410 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99420 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99430 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99440 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99450 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99460 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99470 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99480 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99490 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99500 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99510 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99520 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99530 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99540 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99550 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99560 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99570 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99580 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99590 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99600 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99610 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99620 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99630 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99640 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99650 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99660 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99670 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99680 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99690 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99700 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99710 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99720 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99730 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99740 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99750 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99760 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99770 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99780 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99790 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99800 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99810 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99820 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99830 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99840 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99850 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99860 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99870 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99880 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99890 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99900 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99910 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99920 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99930 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99940 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99950 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99960 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99970 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99980 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Epoch : 99990 | Loss : 0.008932482451200485 | Test Loss : 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n",
            "Loss : 0.008932482451200485\n",
            "Loss : 0.0025885067880153656\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 100000\n",
        "\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_0.train()\n",
        "\n",
        "  y_pred = model_0(X_train)\n",
        "\n",
        "  loss = loss_fn(y_pred,y_train)\n",
        "  print(f\"Loss : {loss}\")\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  model_0.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_0(X_test)\n",
        "\n",
        "    test_loss = loss_fn(test_pred,y_test)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    print(f\"Epoch : {epoch} | Loss : {loss} | Test Loss : {test_loss}\")\n",
        "\n",
        "    #printing out model state dicct\n",
        "    print(model_0.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg5hN0EtEV7X"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new = model_0(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQxnZ87NEV4c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4gyCWZUQAk5"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "vA0ZlrPvQAh_",
        "outputId": "9b65e52d-9593-4509-c748-5d93050d22f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7efb883d5970>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(epoch_count,np.array(torch.tensor(loss_values).numpy()),label=\"Train Loss\")\n",
        "plt.plot(epoch_count,test_loss_values,label=\"Test Loss\")\n",
        "plt.title(\"Training and Test Loss Curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJJT2xrY7IT8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F2fsQcd7IP6",
        "outputId": "811d1a86-385b-4464-d010-509997010779"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSDQ-36v7IOa",
        "outputId": "f5bb8d71-8811-4b96-e952-24aa9b04e17c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6WKdDYl6wnU",
        "outputId": "3184595b-b85c-426d-a3e2-6d5f5b9bf295"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbkDFLzi6wam",
        "outputId": "8e47dc0f-4e8d-482e-aed3-5c611d77217a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PGxaz9o6gae",
        "outputId": "843d944e-97ca-403a-ade3-740b043df3aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6cLIkUZ6gXO",
        "outputId": "0a8eaacb-7928-4afa-abe0-b81e44e1d4ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLK2U8vC6gUP",
        "outputId": "824675c3-b1e9-4bd5-ecaa-4612c36b5f63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7, 0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "weight,bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfRNegzx6lGA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "xj05bFDoErxQ",
        "outputId": "95c5f489-961a-4293-b582-6ed5682945b5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_predictions(predictions=y_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "murl6dxOEruW",
        "outputId": "9ad28a15-d163-4d10-9492-f91d620d22b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_predictions(predictions=y_preds_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "UbMv0Z9YE0sD",
        "outputId": "373f8301-ca41-4d9a-f2ce-4eea6ebab4d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGbCAYAAADgEhWsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hU9bn28fsh4RBOAhJECAIqCoKIEK1aFbRYUUTaWgvotvDWLfECduv2SLUCoi212rKtRgu2SqtSFUQ3L1LwLRsUW8CEk4VwKCLIIULQbhWUQ8jz/jFpmoQkM8maUzLfz3XNlay1fjPrF1aQ2zVr3WPuLgAAANRNo0RPAAAAoD4jTAEAAARAmAIAAAiAMAUAABAAYQoAACCA9ETtuH379t6tW7dE7R4AACBiq1evPuDumVVtS1iY6tatm/Lz8xO1ewAAgIiZ2c7qtvE2HwAAQACEKQAAgAAIUwAAAAEQpgAAAAIgTAEAAASQsLv5wvn888+1f/9+HTt2LNFTQT3RuHFjdejQQa1bt070VAAAKSQpw9Tnn3+uffv2qXPnzsrIyJCZJXpKSHLurq+++kp79uyRJAIVACBukvJtvv3796tz585q3rw5QQoRMTM1b95cnTt31v79+xM9HQBACknKMHXs2DFlZGQkehqohzIyMnhrGAAQV0kZpiRxRgp1wu8NACDewoYpM3vOzPab2YZqtpuZ/drMtpnZ+2bWP/rTBAAASE6RnJmaJWlIDduvkdSj9DFW0jPBpwUAAFA/hA1T7v6OpE9rGDJc0h88ZKWkNmZ2arQmmOrGjBmj6667rlbPGTRokCZMmBCjGQEAgPKicc1UZ0m7yi3vLl13AjMba2b5ZpZfVFQUhV0nDzOr8TFmzJg6ve4TTzyhF198sVbPmTdvnqZNm1an/dXGlClTyn6+9PR0tWvXTpdccommTZumgwcP1uq1duzYITNTfn5+jGYLAEBsxLVnyt1nSpopSdnZ2R7PfcdaYWFh2fcLFizQbbfdVmFd5bsTjx07psaNG4d93ZNOOqnWc2nXrl2tn1NXZ599tpYtWyZ316effqp3331X06ZN03PPPafly5erY8eOcZsLAACJEI0zU3skdSm3nFW6LqV07Nix7NGmTZsK6w4fPqw2bdroj3/8o6688kplZGRoxowZ+uSTTzRq1ChlZWUpIyNDvXv31vPPP1/hdSu/zTdo0CCNGzdO999/v9q3b68OHTro7rvvVklJSYUx5d/m69atmx555BHl5OSodevWysrK0mOPPVZhP1u3btXAgQPVrFkznX322Vq4cKFatmypWbNm1fhzp6enq2PHjjr11FPVu3dv5eTkaMWKFfr000913333lY1btGiRLrvsMrVt21bt2rXT1VdfrU2bNpVt7969uyTpggsukJlp0KBBkqS8vDx985vfVPv27dW6dWtdeumlWrFiRQRHBACQEsaPl9LTQ18TJBphar6k75fe1XeRpM/cvTDck1LRj3/8Y40bN04FBQX61re+pcOHD6t///5asGCBNm7cqB/96EfKycnRkiVLanydl156Senp6frrX/+qp556Sv/1X/+lV155pcbnTJ8+Xeeee67WrFmj++67T/fee29ZKCkpKdG3v/1tpaena+XKlZo1a5YeeughHTlypE4/56mnnqqbb75Zb7zxRlnIO3TokO644w699957WrZsmU466SQNGzZMR48elSS99957kkKhq7CwUPPmzZMkffHFF7rlllu0fPlyvffee+rXr5+uvfZaffLJJ3WaGwCggZkxQzp+PPQ1Udy9xoekP0oqlHRMoeuhbpV0u6TbS7ebpFxJH0j6m6TscK/p7howYIBXp6CgoNpttTVunHtaWuhrvMyZM8dDf7QhH374oUvyxx9/POxzR4wY4bfeemvZ8ujRo33o0KFlywMHDvSLLrqownMGDx5c4TkDBw708ePHly137drVR44cWeE5Z555pj/88MPu7r5o0SJPS0vz3bt3l23/y1/+4pL8+eefr3aukydP9t69e1e57ZlnnnFJvm/fviq3Hzx40Bs1auTLly9393/9GeXl5VW7P3f3kpIS79ixo7/wwgvVjonm7w8AIMnF6R96SfleTaYJe82Uu48Ks90lJe7cWhjlA2tubmLnkp2dXWH5+PHj+vnPf65XXnlFe/bs0ZEjR3T06NGyt7iq07dv3wrLnTp1CvsRKjU9Z/PmzerUqZM6d/7XfQMXXHCBGjWq+4nL0K/Fv0o0P/jgAz344INatWqVioqKVFJSopKSEn300Uc1vs7+/fv14IMPaunSpdq3b5+OHz+ur776KuzzAAApIjc34f/AJ20DerTk5EhpaaGvidaiRYsKy48//rh++ctf6p577tGSJUu0bt06fetb3yp766s6lS9cN7MK10xF6zlBFBQUqHXr1jr55JMlSdddd52Kioo0Y8YMrVq1SmvXrlV6enrYn3X06NHKy8vT9OnT9de//lXr1q1TVlZW2OcBAFLD+DfHK31qusa/mbjzOnG9my8RkiCwVuvdd9/VsGHDdMstt0gKnc3ZunVr2QXs8dKzZ0/t3btXe/fuVadOnSRJ+fn5dQ5bhYWFmj17tr7zne+oUaNG+uSTT7R582Y9/fTTuuKKKyRJa9asUXFxcdlzmjRpIil0tq68d999V7/+9a81dOhQSdK+ffsq3CUJAEhtM1bP0HE/rhmrZyh3aGL+wW/wZ6aS2VlnnaUlS5bo3Xff1ebNmzVhwgR9+OGHcZ/HVVddpbPPPlujR4/W+vXrtXLlSt15551KT08P+1l3xcXF+vjjj1VYWKiNGzdq5syZuvjii9WuXbuyrqu2bduqffv2evbZZ7Vt2za9/fbbuv3225We/q8s36FDB2VkZGjx4sXat2+fPvvsM0mhP6MXX3xRBQUFysvL08iRI8uCFwAAOQNylGZpyhmQuLegCFMJ9JOf/EQXXnihrrnmGl1++eVq0aKFbr755rjPo1GjRnr99dd15MgRXXjhhRo9erQeeOABmZmaNWtW43O3bNmiU089VVlZWbr00kv1/PPPa+zYsVqzZk1Zx1SjRo30yiuv6P3331efPn00fvx4Pfzww2ratGnZ66Snp+vXv/61fvvb36pTp04aPny4JOm5557TwYMHNWDAAI0cOVI/+MEP1K1bt5j9WQAAkkAt6g5yh+aqeFJxws5KSZL980LheMvOzvbq2q43bdqkXr16xXlGKG/9+vXq16+f8vPzNWDAgERPp1b4/QGAei49PXT3WFqaVO6SkEQys9Xunl3VtgZ/zRQi8/rrr6tFixbq0aOHduzYoTvvvFPnnXee+vfvn+ipAQBSTU5O6Db8ZLh7LAKEKUgKlWPed9992rVrl9q2batBgwZp+vTpYa+ZAgAg6pL57rEqcM0UJEnf//73tXXrVn311Vfau3evZs+erVNOOSXR0wIApKBkqDuoDcIUAABIKuXrDuoDwhQAAEgqyVB3UBuEKQAAEB8RVh4kQ91BbRCmAABAfJT/wNwGhDAFAADiI5k+MDeKqEYAAADxUc8qDyLFmal6rFu3bnr88ccTPQ0AACJS3yoPIkWYihIzq/ExZsyYOr/2lClT1KdPnxPW5+Xlady4cQFmHZkxY8aU/RyNGzdWhw4ddMUVVyg3N1fHjh2r1WstW7ZMZqYDBw7EaLYAgGRV3yoPIkWYipLCwsKyx7PPPnvCuieeeCLq+8zMzFTz5s2j/rpVGTx4sAoLC7Vjxw699dZbGjZsmCZPnqzLLrtMhw4disscAABJKsK79Opb5UGkCFNR0rFjx7JHmzZtTlj3zjvvaMCAAWrWrJm6d++uBx54QEePHi17/rx589S3b19lZGSoXbt2GjhwoPbt26dZs2bpoYce0saNG8vODs2aNUvSiW/zmZlmzpypG2+8US1atNDpp5+uF198scI8V61apf79+6tZs2Y6//zztXDhQpmZli1bVuPP17RpU3Xs2FGdO3dWv379dOedd2rZsmVas2aNfvGLX5SNe/HFF3XBBReoVatW6tChg2688Ubt2bNHkrRjxw5dccUVkkJBsPwZu0WLFumyyy5T27Zt1a5dO1199dXatGlTnY4FACDOIrxLr75VHkSKMBUHixcv1s0336wJEyZo48aNeu655zR37lzdf//9kqSPP/5YI0eO1OjRo7Vp0ya98847uuWWWyRJI0aM0F133aWzzz677CzXiBEjqt3X1KlTNXz4cK1fv14jRozQD37wA3300UeSpIMHD+q6665Tz549tXr1av3iF7/QPffcU+efq0+fPhoyZIhee+21snVHjx7VQw89pPXr12vBggU6cOCARo0aJUnq0qVL2diNGzdWOGN36NAh3XHHHXrvvfe0bNkynXTSSRo2bFiFwAkASFIN9C69iLl7Qh4DBgzw6hQUFFS7rbbGLRjnaQ+l+bgF46L2muHMmTPHQ3+0IZdddplPnTq1wpjXX3/dW7Ro4SUlJb569WqX5Dt27Kjy9SZPnuy9e/c+YX3Xrl39scceK1uW5BMnTixbPnbsmGdkZPgLL7zg7u6/+c1vvG3btv7ll1+WjXnppZdcki9durTan2f06NE+dOjQKrfdd999npGRUe1zN23a5JJ8165d7u6+dOlSl+RFRUXVPsfd/eDBg96oUSNfvnx5jeOqEs3fHwAA3N0l5Xs1mabBn5lKhovdVq9erZ/+9Kdq2bJl2eOmm27SoUOH9PHHH+u8887T4MGD1adPH91www165plnVFRUVKd99e3bt+z79PR0ZWZmav/+/ZKkzZs3q0+fPsrIyCgb87WvfS3Qz+buMrOy5TVr1mj48OHq2rWrWrVqpezsbEkqOztWnQ8++EA33XSTzjjjDLVu3VqnnHKKSkpKwj4PAIBEa/BhKhkudispKdHkyZO1bt26ssf777+vv//978rMzFRaWpreeustvfXWW+rbt69+97vfqUePHlq/fn2t99W4ceMKy2amkpKSaP0oJygoKNDpp58uKfRW3dVXX63mzZvrhRdeUF5enhYtWiRJYd+uu+6661RUVKQZM2Zo1apVWrt2rdLT03mbDwDqgYZaeRCpBh+mkuFit/79+2vz5s0688wzT3ikp4d6U81MF198sSZPnqy8vDx16tRJr7zyiiSpSZMmOn78eOB59OzZUxs2bNBXX31Vtu69996r8+tt2LBBixYt0ne/+11JoTNfBw4c0M9+9jNdfvnl6tmzZ9lZsX9q0qSJJFX4eT755BNt3rxZ999/vwYPHqxevXrpiy++UHFxcZ3nBgCIn2R4FyiRGnyYSgaTJk3S7NmzNWnSJG3YsEGbN2/W3Llzde+990qSVq5cqUceeUR5eXn66KOPNH/+fO3atUvnnHOOpNBdezt37tSaNWt04MABHTlypE7zuOmmm5SWlqbbbrtNBQUF+vOf/6yf/exnklThrbqqHDlyRB9//LH27t2r9evX61e/+pUGDRqkAQMG6O6775YknXbaaWratKmeeuopbd++XW+++aYefPDBCq/TtWtXmZnefPNNFRUV6eDBg2rbtq3at2+vZ599Vtu2bdPbb7+t22+/vSxoAgASIMK6Ayk53gVKqOoupor1I14XoCdC5QvQ3d0XL17sl156qWdkZHirVq18wIAB/uSTT7p76OcdMmSId+jQwZs0aeJnnHGGP/roo2XPPXz4sN9www3epk0bl+TPP/+8u1d9AfqcOXMq7LfymBUrVni/fv28SZMm3q9fP587d65L8pUrV1b784wePdoluSRPS0vzk08+2QcOHOhPPvmkHzlypMLYl19+2U8//XRv2rSpX3DBBb5o0aITLnCfOnWqd+zY0c3MR48e7e7uS5Ys8d69e3vTpk29d+/evmjRIm/RokXZz1ob9f33BwCSQlqauxT6ihovQLfQ9vjLzs72/Pz8Krdt2rRJvXr1ivOMUtN///d/69vf/rb279+v9u3bJ3o6UcHvDwBEwfjxod6onJwG+Xl6tWVmq909u6ptvI+SYn7/+9/r9NNPV5cuXbRhwwbdcccdGjZsWIMJUgCAKGmgH0ocC4SpFLNv3z5NnjxZhYWF6tixo4YOHapHH3000dMCAKDe4gL0FHPvvfdqx44dOnLkiHbu3Kmnn35arVq1SvS0AABJJtXrDmqDMAUAAE6Q6nUHtUGYAgAglURYeZDydQe1wN18aHD4/QGAGqSnS8ePhz6YmHLkiNV0Nx9npgAASCU5OaEglcMZp2jhbj4AAFIJlQdRx5kpAACAAAhT9dDcuXMrfJberFmz1LJly0CvuWzZMpmZDhw4EHR6AIAkRuVB9BGmomjMmDEyM5mZGjdurNNPP1133323Dh06FNP9jhgxQtu3b494fLdu3fT4449XWHfJJZeosLBQJ598crSnBwBIIlQeRB9hKsoGDx6swsJCbd++XY888oiefvpp3X333SeMKy4uVrTupMzIyFCHDh0CvUaTJk3UsWPHCme8AAD1CJUHCUOYirKmTZuqY8eO6tKli2666SbdfPPNeuONNzRlyhT16dNHs2bN0hlnnKGmTZvq0KFD+uyzzzR27Fh16NBBrVq10sCBA1W5MuIPf/iDunbtqubNm+u6667Tvn37Kmyv6m2+hQsX6mtf+5oyMjJ08skna9iwYTp8+LAGDRqknTt36p577ik7iyZV/TbfvHnzdO6556pp06bq0qWLfvrTn1YIgN26ddMjjzyinJwctW7dWllZWXrssccqzGPGjBk666yz1KxZM7Vv315XX321irkVFwCib8aMUOXBjJrPOOUOzVXxpGLlDuUi9GghTMVYRkaGjh07Jkn68MMPNXv2bM2ZM0fr169X06ZNNXToUO3Zs0cLFizQ2rVrdfnll+vKK69UYWGhJGnVqlUaM2aMxo4dq3Xr1mnYsGGaNGlSjftctGiRrr/+el111VVavXq1li5dqoEDB6qkpETz5s1TVlaWJk2apMLCwrL9VLZ69WrdeOON+s53vqO//e1v+vnPf65p06bpqaeeqjBu+vTpOvfcc7VmzRrdd999uvfee7VixQpJUn5+vsaPH6/Jkydry5YtWrJkiYYMGRL0jxQAUBUqDxLH3RPyGDBggFenoKCg2m21Nm6ce1pa6GuMjR492ocOHVq2vGrVKj/55JP9e9/7nk+ePNnT09P9448/Ltu+ZMkSb9GihX/55ZcVXue8887zRx991N3dR40a5YMHD66w/dZbb/XQoQt5/vnnvUWLFmXLl1xyiY8YMaLaeXbt2tUfe+yxCuuWLl3qkryoqMjd3W+66Sa/4oorKoyZPHmyd+7cucLrjBw5ssKYM8880x9++GF3d3/ttde8devW/vnnn1c7l1iI6u8PAADuLinfq8k0EZ2ZMrMhZrbFzLaZ2cQqtnc1syVm9r6ZLTOzrChnvrqL8LRntCxatEgtW7ZUs2bNdPHFF+vyyy/Xk08+KUnKysrSKaecUjZ29erV+vLLL5WZmamWLVuWPTZs2KAPPvhAUqjN++KLL66wj8rLla1du1bf+MY3Av0cmzZt0te//vUK6y699FLt2bNHn3/+edm6vn37VhjTqVMn7d+/X5J01VVXqWvXrurevbtuvvlm/f73v9cXX3wRaF4AACSbsGHKzNIk5Uq6RtI5kkaZ2TmVhj0u6Q/u3lfSVEnToj3ROovzac/LL79c69at05YtW3T48GHNmzev7OLwFi1aVBhbUlKiU045RevWravw2Lx5sx5++OG4zLcuyl+k3rhx4xO2lZSUSJJatWqlNWvW6NVXX9Vpp52madOmqWfPntq7d29c5wsAqYDKg8SJ5MzUhZK2uft2dz8q6WVJwyuNOUfS/5R+v7SK7YmTmxv67KE4tb02b95cZ555prp27XpC0Kisf//+2rdvnxo1aqQzzzyzwuOfAaxXr15auXJlhedVXq7s/PPP15IlS6rd3qRJEx0/frzG1+jVq5f+8pe/VFj37rvvKisrS61atarxueWlp6fryiuv1LRp0/T+++/r0KFDWrBgQcTPBwBEhsqDxIkkTHWWtKvc8u7SdeWtl/Sd0u+/LamVmZ1QWGRmY80s38zyi4qK6jLfBmXw4MH6+te/ruHDh+tPf/qTPvzwQ61YsUKTJ0/W8uXLJUk//OEP9ec//1nTpk3T3//+dz377LN6/fXXa3zdBx54QHPmzNFPfvITFRQUaOPGjZo+fbq+/PJLSaG78JYvX649e/ZUW9J511136e2339aUKVO0detWvfTSS/rlL3+pe++9N+Kfb8GCBXriiSe0du1a7dy5U7Nnz9YXX3zBhxADQKQirDuQqDxIpGjdzXe3pIFmtlbSQEl7JJ1w6sPdZ7p7trtnZ2ZmRmnX9ZeZaeHChbryyit122236eyzz9b3vvc9bdmyRZ06dZIkXXTRRfrd736nZ555Rn379tW8efM0ZcqUGl/32muv1euvv64//elPOv/88zVw4EAtXbpUjRqFDvfUqVO1a9cunXHGGaruOPTv319z5szRa6+9pj59+mjixImaOHGiJkyYEPHP16ZNG73xxhsaPHiwevbsqccff1y//e1vddlll0X8GgCQ0mpx3S+VB4ljHqY40swuljTF3a8uXf6xJLl7lddFmVlLSZvdvcaL0LOzs71yn9I/bdq0ibMXqDN+fwA0GOPHh4JUTg4fTpxgZrba3bOr2hbJmak8ST3MrLuZNZE0UtL8Sjtob2b/fK0fS3ouyIQBAIDift0v6iZsmHL3YkkTJC2WtEnSq+6+0cymmtn1pcMGSdpiZlslnSLppzGaLwAAQFKJ6Jopd1/o7me5+xnu/tPSdZPcfX7p93PdvUfpmH939yOxnDQAAKmAuoP6gY+TAQAgSVF3UD8kbZj6Z/EjUBv83gCoFyKsPKDuoH4IezdfrNR0N99HH30kM9Mpp5yixo0bV2jcBqri7jp27Jj27dsnd9dpp52W6CkBQPXS00OVB2lpoQvMkfRqupsvPd6TiURWVpYOHDignTt3qphfMkQoPT1dJ510ktq3b5/oqQBAzXJy/lV5gHovKc9MAQAAJJOgPVMAAACoBmEKAIA4o/KgYSFMAQAQZ1QeNCyEKQAAooXKg5TEBegAAEQLlQcNFhegAwAQDzk5oSBF5UFK4cwUAABAGJyZAgAAiBHCFAAAUULlQWoiTAEAECVUHqQmwhQAAFFC5UFq4gJ0AACAMLgAHQAAIEYIUwAAAAEQpgAAqEGEnxCDFEaYAgCgBjNmhD4hZgY36KEahCkAAGrAJ8QgHO7mAwAACIO7+QAAAGKEMAUAABAAYQoAACAAwhQAICVReYBoIUwBAFISlQeIFsIUACAlUXmAaKEaAQAAIAyqEQAAAGKEMAUAABAAYQoAACAAwhQAoMGg7gCJQJgCADQY1B0gEQhTAIAGg7oDJALVCAAAAGFQjQAAABAjhCkAAIAACFMAAAABRBSmzGyImW0xs21mNrGK7aeZ2VIzW2tm75vZtdGfKgAgVVF5gGQW9gJ0M0uTtFXSVZJ2S8qTNMrdC8qNmSlprbs/Y2bnSFro7t1qel0uQAcARCo9PVR5kJYmFRcnejZIRUEvQL9Q0jZ33+7uRyW9LGl4pTEuqXXp9ydJ2lvXyQIAUBmVB0hm6RGM6SxpV7nl3ZK+VmnMFElvmdl/SGohaXBVL2RmYyWNlaTTTjuttnMFAKSo3NzQA0hG0boAfZSkWe6eJelaSS+Y2Qmv7e4z3T3b3bMzMzOjtGsAAIDEiSRM7ZHUpdxyVum68m6V9KokufsKSc0ktY/GBAEAAJJZJGEqT1IPM+tuZk0kjZQ0v9KYjyR9Q5LMrJdCYaoomhMFAABIRmHDlLsXS5ogabGkTZJedfeNZjbVzK4vHXaXpNvMbL2kP0oa44n6nBoAQL1B5QEaAj6bDwCQMFQeoL7gs/kAAEmJygM0BJyZAgAACIMzUwAAADFCmAIAAAiAMAUAABAAYQoAEFXUHSDVEKYAAFE1Y0ao7mDGjETPBIgPwhQAIKqoO0CqoRoBAAAgDKoRAAAAYoQwBQAAEABhCgAAIADCFAAgIlQeAFUjTAEAIkLlAVA1whQAICJUHgBVoxoBAAAgDKoRAAAAYoQwBQAAEABhCgAAIADCFACkOCoPgGAIUwCQ4qg8AIIhTAFAiqPyAAiGagQAAIAwqEYAAACIEcIUAABAAIQpAACAAAhTANAAUXcAxA9hCgAaIOoOgPghTAFAA0TdARA/VCMAAACEQTUCAABAjBCmAAAAAiBMAQAABECYAoB6hMoDIPkQpgCgHqHyAEg+hCkAqEeoPACSD9UIAAAAYVCNAAAAECOEKQAAgAAIUwAAAAEQpgAgCVB5ANRfEYUpMxtiZlvMbJuZTaxi+3QzW1f62Gpm/xv9qQJAw0XlAVB/hQ1TZpYmKVfSNZLOkTTKzM4pP8bd/9Pd+7l7P0lPSpoXi8kCQENF5QFQf0VyZupCSdvcfbu7H5X0sqThNYwfJemP0ZgcAKSK3FypuDj0FUD9EkmY6ixpV7nl3aXrTmBmXSV1l/Q/1Wwfa2b5ZpZfVFRU27kCAAAknWhfgD5S0lx3P17VRnef6e7Z7p6dmZkZ5V0DAADEXyRhao+kLuWWs0rXVWWkeIsPAACkkEjCVJ6kHmbW3cyaKBSY5lceZGY9JbWVtCK6UwSA+om6AyA1hA1T7l4saYKkxZI2SXrV3Tea2VQzu77c0JGSXvZEfdgfACQZ6g6A1JAeySB3XyhpYaV1kyotT4netACg/svJCQUp6g6Ahs0SdSIpOzvb8/PzE7JvAACA2jCz1e6eXdU2Pk4GAAAgAMIUAABAAIQpAACAAAhTAFBLVB4AKI8wBQC1ROUBgPIIUwBQSzk5UloalQcAQqhGAAAACINqBAAAgBghTAEAAARAmAIAAAiAMAUApag8AFAXhCkAKEXlAYC6IEwBQCkqDwDUBdUIAAAAYVCNAAAAECOEKQAAgAAIUwAAAAEQpgA0aNQdAIg1whSABo26AwCxRpgC0KBRdwAg1qhGAAAACINqBAAAgBghTAEAAARAmAIAAAiAMAWgXqLyAECyIEwBqJeoPACQLAhTAOolKg8AJAuqEQAAAMKgGgEAACBGCJfAdMsAAA2jSURBVFMAAAABEKYAAAACIEwBSCpUHgCobwhTAJIKlQcA6hvCFICkQuUBgPqGagQAAIAwqEYAAACIEcIUAABAAIQpAACAAAhTAGKOugMADRlhCkDMUXcAoCGLKEyZ2RAz22Jm28xsYjVjvmdmBWa20cxmR3eaAOoz6g4ANGRhqxHMLE3SVklXSdotKU/SKHcvKDemh6RXJV3p7v8wsw7uvr+m16UaAQAA1BdBqxEulLTN3be7+1FJL0saXmnMbZJy3f0fkhQuSAEAADQUkYSpzpJ2lVveXbquvLMknWVmfzGzlWY2pKoXMrOxZpZvZvlFRUV1mzEAAEASidYF6OmSekgaJGmUpGfNrE3lQe4+092z3T07MzMzSrsGAABInEjC1B5JXcotZ5WuK2+3pPnufszdP1ToGqse0ZkigGRF5QEARBam8iT1MLPuZtZE0khJ8yuNeUOhs1Iys/YKve23PYrzBJCEqDwAgAjClLsXS5ogabGkTZJedfeNZjbVzK4vHbZY0idmViBpqaR73P2TWE0aQHKg8gAAIqhGiBWqEQAAQH0RtBoBAAAA1SBMAQAABECYAgAACIAwBaAC6g4AoHYIUwAqoO4AAGqHMAWgAuoOAKB2qEYAAAAIg2oEAACAGCFMAQAABECYAgAACIAwBaQIKg8AIDYIU0CKoPIAAGKDMAWkCCoPACA2qEYAAAAIg2oEAACAGCFMAQAABECYAgAACIAwBdRzVB4AQGIRpoB6jsoDAEgswhRQz1F5AACJRTUCAABAGFQjAAAAxAhhCgAAIADCFAAAQACEKSAJUXcAAPUHYQpIQtQdAED9QZgCkhB1BwBQf1CNAAAAEAbVCAAAADFCmAIAAAiAMAUAABAAYQqIIyoPAKDhIUwBcUTlAQA0PIQpII6oPACAhodqBAAAgDCoRgAAAIgRwhQAAEAAhCkAAIAACFNAFFB5AACpizAFRAGVBwCQughTQBRQeQAAqSuiMGVmQ8xsi5ltM7OJVWwfY2ZFZrau9PHv0Z8qkLxyc6Xi4tBXAEBqSQ83wMzSJOVKukrSbkl5Zjbf3QsqDX3F3SfEYI4AAABJK5IzUxdK2ubu2939qKSXJQ2P7bQAAADqh0jCVGdJu8ot7y5dV9kNZva+mc01sy5VvZCZjTWzfDPLLyoqqsN0AQAAkku0LkD/v5K6uXtfSf9P0u+rGuTuM909292zMzMzo7RrIDaoOwAARCKSMLVHUvkzTVml68q4+yfufqR08beSBkRnekDiUHcAAIhEJGEqT1IPM+tuZk0kjZQ0v/wAMzu13OL1kjZFb4pAYlB3AACIRNi7+dy92MwmSFosKU3Sc+6+0cymSsp39/mSfmhm10sqlvSppDExnDMQF7m5VB0AAMIzd0/IjrOzsz0/Pz8h+wYAAKgNM1vt7tlVbaMBHQAAIADCFAAAQACEKaQcKg8AANFEmELKofIAABBNhCmkHCoPAADRxN18AAAAYXA3HwAAQIwQpgAAAAIgTAEAAARAmEKDQeUBACARCFNoMKg8AAAkAmEKDQaVBwCARKAaAQAAIAyqEQAAAGKEMAUAABAAYQoAACAAwhSSGnUHAIBkR5hCUqPuAACQ7AhTSGrUHQAAkh3VCAAAAGFQjQAAABAjhCkAAIAACFMAAAABEKaQEFQeAAAaCsIUEoLKAwBAQ0GYQkJQeQAAaCioRgAAAAiDagQAAIAYIUwBAAAEQJgCAAAIgDCFqKLyAACQaghTiCoqDwAAqYYwhaii8gAAkGqoRgAAAAiDagQAAIAYIUwBAAAEQJgCAAAIgDCFsKg7AACgeoQphEXdAQAA1SNMISzqDgAAqB7VCAAAAGEErkYwsyFmtsXMtpnZxBrG3WBmbmZV7gwAAKChCRumzCxNUq6kaySdI2mUmZ1TxbhWkn4kaVW0JwkAAJCsIjkzdaGkbe6+3d2PSnpZ0vAqxj0s6VFJh6M4PwAAgKQWSZjqLGlXueXdpevKmFl/SV3c/c2aXsjMxppZvpnlFxUV1XqyiC4qDwAACC7w3Xxm1kjSryTdFW6su89092x3z87MzAy6awRE5QEAAMFFEqb2SOpSbjmrdN0/tZLUR9IyM9sh6SJJ87kIPflReQAAQHBhqxHMLF3SVknfUChE5Um6yd03VjN+maS73b3G3gOqEQAAQH0RqBrB3YslTZC0WNImSa+6+0Yzm2pm10d3qgAAAPVLeiSD3H2hpIWV1k2qZuyg4NMCAACoH/g4GQAAgAAIUw0QlQcAAMQPYaoBovIAAID4IUw1QFQeAAAQP2GrEWKFagQAAFBfBKpGAAAAQPUIUwAAAAEQpgAAAAIgTNUT1B0AAJCcCFP1BHUHAAAkJ8JUPUHdAQAAyYlqBAAAgDCoRgAAAIgRwhQAAEAAhCkAAIAACFMJRuUBAAD1G2Eqwag8AACgfiNMJRiVBwAA1G9UIwAAAIRBNQIAAECMEKYAAAACIEwBAAAEQJiKAeoOAABIHYSpGKDuAACA1EGYigHqDgAASB1UIwAAAIRBNQIAAECMEKYAAAACIEwBAAAEQJiqBSoPAABAZYSpWqDyAAAAVEaYqgUqDwAAQGVUIwAAAIRBNQIAAECMEKYAAAACIEwBAAAEQJgSlQcAAKDuCFOi8gAAANQdYUpUHgAAgLqjGgEAACCMwNUIZjbEzLaY2TYzm1jF9tvN7G9mts7M3jWzc4JOGgAAoD4IG6bMLE1SrqRrJJ0jaVQVYWm2u5/r7v0k/ULSr6I+UwAAgCQUyZmpCyVtc/ft7n5U0suShpcf4O6fl1tsISkx7x0CAADEWSRhqrOkXeWWd5euq8DMxpvZBwqdmfphdKZXd9QdAACAeIja3XzunuvuZ0i6T9JPqhpjZmPNLN/M8ouKiqK16ypRdwAAAOIhkjC1R1KXcstZpeuq87Kkb1W1wd1nunu2u2dnZmZGPss6oO4AAADEQyRhKk9SDzPrbmZNJI2UNL/8ADPrUW5xqKS/R2+KdZObKxUXh74CAADESnq4Ae5ebGYTJC2WlCbpOXffaGZTJeW7+3xJE8xssKRjkv4haXQsJw0AAJAswoYpSXL3hZIWVlo3qdz3P4ryvAAAAOoFPk4GAAAgAMIUAABAAIQpAACAAAhTAAAAARCmAAAAAiBMAQAABECYAgAACIAwBQAAEABhCgAAIADCFAAAQACEKQAAgAAIUwAAAAGYuydmx2ZFknbGeDftJR2I8T5Qdxyf5MWxSW4cn+TG8UleQY5NV3fPrGpDwsJUPJhZvrtnJ3oeqBrHJ3lxbJIbxye5cXySV6yODW/zAQAABECYAgAACKChh6mZiZ4AasTxSV4cm+TG8UluHJ/kFZNj06CvmQIAAIi1hn5mCgAAIKYIUwAAAAE0iDBlZkPMbIuZbTOziVVsb2pmr5RuX2Vm3eI/y9QVwfG508wKzOx9M1tiZl0TMc9UFO7YlBt3g5m5mXG7dxxFcnzM7Hulf382mtnseM8xVUXw37XTzGypma0t/W/btYmYZyoys+fMbL+Zbahmu5nZr0uP3ftm1j/oPut9mDKzNEm5kq6RdI6kUWZ2TqVht0r6h7ufKWm6pEfjO8vUFeHxWSsp2937Spor6RfxnWVqivDYyMxaSfqRpFXxnWFqi+T4mFkPST+W9HV37y3pjrhPNAVF+HfnJ5JedffzJY2U9HR8Z5nSZkkaUsP2ayT1KH2MlfRM0B3W+zAl6UJJ29x9u7sflfSypOGVxgyX9PvS7+dK+oaZWRznmMrCHh93X+ruX5YurpSUFec5pqpI/u5I0sMK/Q/I4XhODhEdn9sk5br7PyTJ3ffHeY6pKpJj45Jal35/kqS9cZxfSnP3dyR9WsOQ4ZL+4CErJbUxs1OD7LMhhKnOknaVW95duq7KMe5eLOkzSSfHZXaI5PiUd6ukP8V0RvinsMem9PR3F3d/M54Tg6TI/u6cJeksM/uLma00s5r+bxzRE8mxmSLp38xst6SFkv4jPlNDBGr771JY6YGmA0SRmf2bpGxJAxM9F0hm1kjSrySNSfBUUL10hd6qGKTQGd13zOxcd//fhM4KkjRK0ix3/6WZXSzpBTPr4+4liZ4Yoq8hnJnaI6lLueWs0nVVjjGzdIVOuX4Sl9khkuMjMxss6QFJ17v7kTjNLdWFOzatJPWRtMzMdki6SNJ8LkKPm0j+7uyWNN/dj7n7h5K2KhSuEFuRHJtbJb0qSe6+QlIzhT5kF4kX0b9LtdEQwlSepB5m1t3Mmih0od/8SmPmSxpd+v13Jf2P01YaL2GPj5mdL2mGQkGKaz7ip8Zj4+6fuXt7d+/m7t0Uup7tenfPT8x0U04k/217Q6GzUjKz9gq97bc9npNMUZEcm48kfUOSzKyXQmGqKK6zRHXmS/p+6V19F0n6zN0Lg7xgvX+bz92LzWyCpMWS0iQ95+4bzWyqpHx3ny/pdwqdYt2m0EVpIxM349QS4fF5TFJLSXNK7wv4yN2vT9ikU0SExwYJEuHxWSzpm2ZWIOm4pHvcnbPuMRbhsblL0rNm9p8KXYw+hv+Jjw8z+6NC/5PRvvSatcmSGkuSu/9GoWvYrpW0TdKXkv5P4H1ybAEAAOquIbzNBwAAkDCEKQAAgAAIUwAAAAEQpgAAAAIgTAEAAARAmAIAAAiAMAUAABDA/wfM68xkwmJv0AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_predictions(predictions=y_preds_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpUD_LjRFOvK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZmPZ6-3FOsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eceb407-6809-4efe-db62-627c70eafbb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/01_pytorch_workflow_model_0.pth\n",
            "saving model to path : models/01_pytorch_workflow_model_0.pth\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
        "\n",
        "print(MODEL_SAVE_PATH)\n",
        "\n",
        "print(f\"saving model to path : {MODEL_SAVE_PATH}\")\n",
        "\n",
        "torch.save(obj=model_0.state_dict(),f=MODEL_SAVE_PATH)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZlZofTNFOpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ad71be-ea7c-4cfa-ce48-ea71696edbc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegressionModel()"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model_0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwXRr500-D_U",
        "outputId": "8fe26a2e-2f27-47f6-91ff-bd4aaafa32d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "-rw-r--r-- 1 root root 1207 Jan 20 02:26 01_pytorch_workflow_model_0.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iSaigM04BOQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trPE_bK-CDW0",
        "outputId": "3156f2e3-c4ef-48a9-bb3e-b2740061e7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0 = LinearRegressionModel()"
      ],
      "metadata": {
        "id": "cC_tnb2YCDT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJFXwseSCM0f",
        "outputId": "ec7ad3fa-706d-4581-a55b-0aa90fb1e762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqg1xcpzCR1o",
        "outputId": "53325a27-d1de-4ec3-829d-ae207f259c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbd7zwjnC5ZH",
        "outputId": "e0cb012c-ea5d-488c-cb3e-80fc01b2dcd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_preds = loaded_model_0(X_test)\n",
        "\n",
        "loaded_model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PEgxAijC9uG",
        "outputId": "e300b4d3-e9fd-4158-90cd-115677191c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8685],\n",
              "        [0.8825],\n",
              "        [0.8965],\n",
              "        [0.9105],\n",
              "        [0.9245],\n",
              "        [0.9384],\n",
              "        [0.9524],\n",
              "        [0.9664],\n",
              "        [0.9804],\n",
              "        [0.9944]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds == loaded_model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE3jf3N8D-td",
        "outputId": "a60cb120-6382-4b36-d477-55ccb4830c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUdQTfkSEUIP",
        "outputId": "38a9d6f1-cb1e-4917-e9fc-c89b869ad17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8685],\n",
              "        [0.8825],\n",
              "        [0.8965],\n",
              "        [0.9105],\n",
              "        [0.9245],\n",
              "        [0.9384],\n",
              "        [0.9524],\n",
              "        [0.9664],\n",
              "        [0.9804],\n",
              "        [0.9944]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds == loaded_model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EHZGCOeE71h",
        "outputId": "aa1e1974-a6f2-4e72-b7e7-2acea0f23d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6t3FEpDRFB4y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy+b++vMpD1W377HAjmJfq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}